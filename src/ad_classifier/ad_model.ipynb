{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NorzUtvsSZPG"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rgKkuEKSUYl",
        "outputId": "4c57d7c5-ac0a-4489-d7af-b8d48ce807ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Get Dataset\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/ADNI_MANUAL_DATASET.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIQXX-L6KDjX"
      },
      "source": [
        "## Define Config\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAD3s1AtihY3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALzkpBSJJ__F"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [200, 200]\n",
        "CLASS_NAMES = [\"AD\", \"CN\", \"MCI\", \"pMCI\"]\n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/models\"\n",
        "\n",
        "DATASET_PATH = \"/content/dataset/ADNI_MANUAL_DATASET\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hek1heu_Sq-a"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXAqgCV1Sr8Q"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from datetime import datetime\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yehsoKeIKhon"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2ebB7C8KlKZ"
      },
      "outputs": [],
      "source": [
        "#------------------------------------COGNINET-------------------------------#\n",
        "\n",
        "def convolutional_block(filters):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.SeparableConv2D(\n",
        "            filters, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.SeparableConv2D(\n",
        "            filters, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPool2D()\n",
        "    ]\n",
        "    )\n",
        "\n",
        "\n",
        "def dense_block(units, dropout_rate):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(units, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "\n",
        "def cogni_net():\n",
        "    model = tf.keras.Sequential([\n",
        "            tf.keras.Input(shape=(*IMAGE_SIZE, 1)),\n",
        "\n",
        "            tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "            tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "            tf.keras.layers.MaxPool2D(),\n",
        "\n",
        "            convolutional_block(32),\n",
        "            convolutional_block(64),\n",
        "\n",
        "            convolutional_block(128),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "            convolutional_block(256),\n",
        "            tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "            tf.keras.layers.Flatten(),\n",
        "            dense_block(512, 0.7),\n",
        "            dense_block(128, 0.5),\n",
        "            dense_block(64, 0.3),\n",
        "\n",
        "            tf.keras.layers.Dense(\n",
        "                4, activation='softmax')\n",
        "        ])\n",
        "    return model\n",
        "\n",
        "#------------------------------------VGGNET-------------------------------#\n",
        "\n",
        "def vgg_net():\n",
        "    input = tf.keras.Input(shape =(*IMAGE_SIZE, 1))\n",
        "    # 1st Conv Block\n",
        "    x = tf.keras.layers.Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(input)\n",
        "    x = tf.keras.layers.Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    # 2nd Conv Block\n",
        "    x = tf.keras.layers.Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    # 3rd Conv block\n",
        "    x = tf.keras.layers.Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    # 4th Conv block\n",
        "\n",
        "    x = tf.keras.layers.Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    # 5th Conv block\n",
        "\n",
        "    x = tf.keras.layers.Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.MaxPool2D(pool_size =2, strides =2, padding ='same')(x)\n",
        "\n",
        "    # Fully connected layers\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(units = 4096, activation ='relu')(x)\n",
        "    x = tf.keras.layers.Dense(units = 4096, activation ='relu')(x)\n",
        "    output = tf.keras.layers.Dense(units = 4, activation ='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model (inputs=input, outputs =output)\n",
        "\n",
        "    return model\n",
        "\n",
        "#------------------------------------DENSENET-------------------------------#\n",
        "\n",
        "\n",
        "def bn_rl_conv(x,filters,kernel=1,strides=1):\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.Conv2D(filters, kernel, strides=strides,padding = 'same')(x)\n",
        "    return x\n",
        "\n",
        "def dense_block(x, repetition, filters=32):\n",
        "\n",
        "   for _ in range(repetition):\n",
        "        y = bn_rl_conv(x, 4*filters)\n",
        "        y = bn_rl_conv(y, filters, 3)\n",
        "        x = tf.keras.layers.concatenate([y,x])\n",
        "   return x\n",
        "\n",
        "def transition_layer(x):\n",
        "\n",
        "    x = bn_rl_conv(x, tf.keras.backend.int_shape(x)[-1] //2 )\n",
        "    x = tf.keras.layers.AvgPool2D(2, strides = 2, padding = 'same')(x)\n",
        "    return x\n",
        "\n",
        "def dense_net():\n",
        "    input = tf.keras.Input(shape =(*IMAGE_SIZE, 1))\n",
        "    x = tf.keras.layers.Conv2D(64, 7, strides = 2, padding = 'same')(input)\n",
        "    x = tf.keras.layers.MaxPool2D(3, strides = 2, padding = 'same')(x)\n",
        "\n",
        "    for repetition in [6,12,24,16]:\n",
        "        d = dense_block(x, repetition)\n",
        "        x = transition_layer(d)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(d)\n",
        "    output = tf.keras.layers.Dense(4, activation = 'softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(input, output)\n",
        "    return model\n",
        "\n",
        "# ------------------------------------RESNET-------------------------------#\n",
        "\n",
        "def residual_module(data,\n",
        "                    filters,\n",
        "                    stride,\n",
        "                    reduce=False,\n",
        "                    reg=0.0001,\n",
        "                    bn_eps=2e-5,\n",
        "                    bn_momentum=0.9):\n",
        "    bn_1 = tf.keras.layers.BatchNormalization(axis=-1,\n",
        "                              epsilon=bn_eps,\n",
        "                           momentum=bn_momentum)(data)\n",
        "    act_1 = tf.keras.layers.ReLU()(bn_1)\n",
        "    conv_1 = tf.keras.layers.Conv2D(filters=int(filters / 4.),\n",
        "                    kernel_size=(1, 1),\n",
        "                    use_bias=False,\n",
        "                    kernel_regularizer=tf.keras.regularizers.l2(reg))(act_1)\n",
        "\n",
        "    bn_2 = tf.keras.layers.BatchNormalization(axis=-1,\n",
        "                              epsilon=bn_eps,\n",
        "                         momentum=bn_momentum)(conv_1)\n",
        "    act_2 = tf.keras.layers.ReLU()(bn_2)\n",
        "    conv_2 = tf.keras.layers.Conv2D(filters=int(filters / 4.),\n",
        "                    kernel_size=(3, 3),\n",
        "                    strides=stride,\n",
        "                    padding='same',\n",
        "                    use_bias=False,\n",
        "                    kernel_regularizer=tf.keras.regularizers.l2(reg))(act_2)\n",
        "    bn_3 = tf.keras.layers.BatchNormalization(axis=-1,\n",
        "                              epsilon=bn_eps,\n",
        "                              momentum=bn_momentum)(conv_2)\n",
        "    act_3 = tf.keras.layers.ReLU()(bn_3)\n",
        "    conv_3 = tf.keras.layers.Conv2D(filters=filters,\n",
        "                    kernel_size=(1, 1),\n",
        "                    use_bias=False,\n",
        "                    kernel_regularizer=tf.keras.regularizers.l2(reg))(act_3)\n",
        "\n",
        "    if reduce:\n",
        "        shortcut = tf.keras.layers.Conv2D(filters=filters,\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=stride,\n",
        "                          use_bias=False,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(reg))(act_1)\n",
        "\n",
        "    x = tf.keras.layers.Add()([conv_3, shortcut])\n",
        "    return x\n",
        "\n",
        "def resnet(input_shape,\n",
        "                 classes,\n",
        "                 stages,\n",
        "                 filters,\n",
        "                 reg=1e-3,\n",
        "                 bn_eps=2e-5,\n",
        "                 bn_momentum=0.9):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.BatchNormalization(axis=-1,\n",
        "                           epsilon=bn_eps,\n",
        "                           \n",
        "                         momentum=bn_momentum)(inputs)\n",
        "    x = tf.keras.layers.Conv2D(filters[0], (3, 3),\n",
        "               use_bias=False,\n",
        "               padding='same',\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(reg))(x)\n",
        "    \n",
        "    for i in range(len(stages)):\n",
        "        stride = (1, 1) if i == 0 else (2, 2)\n",
        "        x = residual_module(data=x,\n",
        "                            filters=filters[i + 1],\n",
        "                            stride=stride,\n",
        "                            reduce=True,\n",
        "                            bn_eps=bn_eps,\n",
        "                            bn_momentum=bn_momentum)\n",
        "        for j in range(stages[i] - 1):\n",
        "            x = residual_module(data=x,\n",
        "                                filters=filters[i + \n",
        "                                               1],\n",
        "                                stride=(1, 1),\n",
        "                                bn_eps=bn_eps,\n",
        "                                \n",
        "                            bn_momentum=bn_momentum)\n",
        "            \n",
        "    x = tf.keras.layers.BatchNormalization(axis=-1,\n",
        "                           epsilon=bn_eps,\n",
        "                           momentum=bn_momentum)(x)\n",
        "    x = tf.keras.layers.ReLU()(x)\n",
        "    x = tf.keras.layers.AveragePooling2D((8, 8))(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "    x = tf.keras.layers.Softmax()(x)\n",
        "    return tf.keras.Model(inputs, x, name='resnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xobk0Ggc80IO"
      },
      "source": [
        "# Hardware Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waQHN7ZN82Li"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    # Limit GPU memory growth\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds7HNUkoKrXO"
      },
      "source": [
        "# Main Model Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMUaBqDjKtGq",
        "outputId": "efcdcb75-1790-44a2-bccc-14b64444474a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "STRATEGY = tf.distribute.get_strategy()\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "BATCH_SIZE = 16 * STRATEGY.num_replicas_in_sync\n",
        "EPOCHS = 50\n",
        "\n",
        "MODEL_NAME = \"DENSENET\"\n",
        "\n",
        "\n",
        "base_dir = f\"{MODEL_SAVE_PATH}/{MODEL_NAME}-{datetime.now().strftime('%Y-%m-%d-%H:%M')}\"\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "with open(f\"{base_dir}/log.log\", \"w\") as sys.stdout:\n",
        "  print(\"REPLICAS: \", STRATEGY.num_replicas_in_sync)\n",
        "\n",
        "  train_ds = image_dataset_from_directory(\n",
        "      DATASET_PATH,\n",
        "      labels=\"inferred\",\n",
        "      label_mode=\"categorical\",\n",
        "      image_size=IMAGE_SIZE,\n",
        "      color_mode=\"grayscale\",\n",
        "      validation_split=0.2,\n",
        "      subset=\"training\",\n",
        "      seed=1337\n",
        "  ).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  validation_ds = image_dataset_from_directory(\n",
        "      DATASET_PATH,\n",
        "      labels=\"inferred\",\n",
        "      label_mode=\"categorical\",\n",
        "      image_size=IMAGE_SIZE,\n",
        "      color_mode=\"grayscale\",\n",
        "      validation_split=0.2,\n",
        "      subset=\"validation\",\n",
        "      seed=1337\n",
        "  ).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  with STRATEGY.scope():\n",
        "      model = dense_net()\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "  # Defining Callbacks\n",
        "  save_best = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=f\"{base_dir}/model.h5\", monitor='val_loss', save_best_only=True)\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "      patience=10, monitor='val_accuracy', factor=0.6, min_lr=0.0000001)\n",
        "\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      validation_data=validation_ds,\n",
        "      epochs=EPOCHS,\n",
        "      callbacks=[save_best, reduce_lr]\n",
        "  )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
